{"cells":[{"cell_type":"markdown","id":"c3f0e974-faf8-458f-bf2a-06a469d0ea5e","metadata":{"id":"c3f0e974-faf8-458f-bf2a-06a469d0ea5e"},"source":["![car](assets/car.jpg)\n","\n","Insurance companies invest a lot of [time and money](https://www.accenture.com/_acnmedia/pdf-84/accenture-machine-leaning-insurance.pdf) into optimizing their pricing and accurately estimating the likelihood that customers will make a claim. In many countries insurance it is a legal requirement to have car insurance in order to drive a vehicle on public roads, so the market is very large!\n","\n","Knowing all of this, On the Road car insurance have requested your services in building a model to predict whether a customer will make a claim on their insurance during the policy period. As they have very little expertise and infrastructure for deploying and monitoring machine learning models, they've asked you to identify the single feature that results in the best performing model, as measured by accuracy, so they can start with a simple model in production.\n","\n","They have supplied you with their customer data as a csv file called `car_insurance.csv`, along with a table detailing the column names and descriptions below."]},{"cell_type":"markdown","id":"8928ffdf-25d6-4ad9-909f-0dd8d10b9a42","metadata":{"id":"8928ffdf-25d6-4ad9-909f-0dd8d10b9a42"},"source":["\n","\n","## The dataset\n","\n","| Column | Description |\n","|--------|-------------|\n","| `id` | Unique client identifier |\n","| `age` | Client's age: <br> <ul><li>`0`: 16-15</li><li>`1`: 26-39</li><li>`2`: 40-64</li><li>`3`: 65+</li></ul> |\n","| `gender` | Client's gender: <br> <ul><li>`0`: Female</li><li>`1`: Male</li></ul> |\n","| `driving_experience` | Years the client has been driving: <br> <ul><li>`0`: 0-9</li><li>`1`: 10-19</li><li>`2`: 20-29</li><li>`3`: 30+</li></ul> |\n","| `education` | Client's level of education: <br> <ul><li>`0`: No education</li><li>`1`: High school</li><li>`2`: University</li></ul> |\n","| `income` | Client's income level: <br> <ul><li>`0`: Poverty</li><li>`1`: Working class</li><li>`2`: Middle class</li><li>`3`: Upper class</li></ul> |\n","| `credit_score` | Client's credit score (between zero and one) |\n","| `vehicle_ownership` | Client's vehicle ownership status: <br><ul><li>`0`: Does not own their vehilce (paying off finance)</li><li>`1`: Owns their vehicle</li></ul> |\n","| `vehcile_year` | Year of vehicle registration: <br><ul><li>`0`: Before 2015</li><li>`1`: 2015 or later</li></ul> |\n","| `married` | Client's marital status: <br><ul><li>`0`: Not married</li><li>`1`: Married</li></ul> |\n","| `children` | Client's number of children |\n","| `postal_code` | Client's postal code |\n","| `annual_mileage` | Number of miles driven by the client each year |\n","| `vehicle_type` | Type of car: <br> <ul><li>`0`: Sedan</li><li>`1`: Sports car</li></ul> |\n","| `speeding_violations` | Total number of speeding violations received by the client |\n","| `duis` | Number of times the client has been caught driving under the influence of alcohol |\n","| `past_accidents` | Total number of previous accidents the client has been involved in |\n","| `outcome` | Whether the client made a claim on their car insurance (response variable): <br><ul><li>`0`: No claim</li><li>`1`: Made a claim</li></ul> |"]},{"cell_type":"markdown","id":"9a74c8a4-42c7-4c4c-8338-7538461f4078","metadata":{"id":"9a74c8a4-42c7-4c4c-8338-7538461f4078"},"source":["- Identify the single feature of the data that is the best predictor of whether a customer will put in a claim (the `\"outcome\"` column), excluding the `\"id\"` column.\n","- Store as a DataFrame called `best_feature_df`, containing columns named `\"best_feature\"` and `\"best_accuracy\"` with the name of the feature with the highest accuracy, and the respective accuracy score."]},{"cell_type":"markdown","id":"9ba07dc8-bb48-47b4-b701-f06dd0008b88","metadata":{"id":"9ba07dc8-bb48-47b4-b701-f06dd0008b88"},"source":["In order to get the feature with the best accuracy we need to follow the next steps:\n","1. Select the features from the data frame for which we are going to calculate the accuracy.\n","2. Calculate a model per feature.\n","    - In this case we are using **logistic regression** since we are dealing with binary outcome variables (in the `outcome` column), and the features are ordinal categorical with values like 0, 1, 2, 3. Logistic regression is weel-suited for binary classification problems, and it can handle ordinal categorical features like the ones in `car_insurance.csv`.\n","3. Compute accuracy through the confusion matrix"]},{"cell_type":"code","execution_count":1,"id":"d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7","metadata":{"executionCancelledAt":null,"executionTime":40,"id":"d0eb4f16-5a99-460d-a5ba-706b7ef0bbe7","lastExecutedAt":1706985812446,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required modules\nimport pandas as pd\nimport numpy as np\nfrom statsmodels.formula.api import logit\n\n# Read data\ncars = pd.read_csv(\"car_insurance.csv\")\n# Check data columns\nprint(cars.info())","outputId":"1395092f-513b-423d-8e1b-82444a1df9ff","outputsMetadata":{"0":{"height":537,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 18 columns):\n"," #   Column               Non-Null Count  Dtype  \n","---  ------               --------------  -----  \n"," 0   id                   10000 non-null  int64  \n"," 1   age                  10000 non-null  int64  \n"," 2   gender               10000 non-null  int64  \n"," 3   driving_experience   10000 non-null  object \n"," 4   education            10000 non-null  object \n"," 5   income               10000 non-null  object \n"," 6   credit_score         9018 non-null   float64\n"," 7   vehicle_ownership    10000 non-null  float64\n"," 8   vehicle_year         10000 non-null  object \n"," 9   married              10000 non-null  float64\n"," 10  children             10000 non-null  float64\n"," 11  postal_code          10000 non-null  int64  \n"," 12  annual_mileage       9043 non-null   float64\n"," 13  vehicle_type         10000 non-null  object \n"," 14  speeding_violations  10000 non-null  int64  \n"," 15  duis                 10000 non-null  int64  \n"," 16  past_accidents       10000 non-null  int64  \n"," 17  outcome              10000 non-null  float64\n","dtypes: float64(6), int64(7), object(5)\n","memory usage: 1.4+ MB\n"]}],"source":["# Import required modules\n","import pandas as pd\n","import numpy as np\n","from statsmodels.formula.api import logit\n","\n","# Read data\n","cars = pd.read_csv(\"data/car_insurance.csv\")\n","# Check data columns\n","cars.info()"]},{"cell_type":"code","execution_count":2,"id":"a076c91a-326c-4bd4-9909-3978faff5d62","metadata":{"executionCancelledAt":null,"executionTime":51,"id":"a076c91a-326c-4bd4-9909-3978faff5d62","lastExecutedAt":1706985812497,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# We can see there are some NaN values in the columns \"credit_score\" and \"annual_mileage\".\n# Fill missing values with the mean\ncars[\"credit_score\"].fillna(cars[\"credit_score\"].mean(), inplace=True)\ncars[\"annual_mileage\"].fillna(cars[\"annual_mileage\"].mean(), inplace=True)\n\n# Check data info again\nprint(cars.info())","outputId":"4ef1bda1-ae2b-4d9c-b8c4-0f849b92b8a4","outputsMetadata":{"0":{"height":537,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 10000 entries, 0 to 9999\n","Data columns (total 18 columns):\n"," #   Column               Non-Null Count  Dtype  \n","---  ------               --------------  -----  \n"," 0   id                   10000 non-null  int64  \n"," 1   age                  10000 non-null  int64  \n"," 2   gender               10000 non-null  int64  \n"," 3   driving_experience   10000 non-null  object \n"," 4   education            10000 non-null  object \n"," 5   income               10000 non-null  object \n"," 6   credit_score         10000 non-null  float64\n"," 7   vehicle_ownership    10000 non-null  float64\n"," 8   vehicle_year         10000 non-null  object \n"," 9   married              10000 non-null  float64\n"," 10  children             10000 non-null  float64\n"," 11  postal_code          10000 non-null  int64  \n"," 12  annual_mileage       10000 non-null  float64\n"," 13  vehicle_type         10000 non-null  object \n"," 14  speeding_violations  10000 non-null  int64  \n"," 15  duis                 10000 non-null  int64  \n"," 16  past_accidents       10000 non-null  int64  \n"," 17  outcome              10000 non-null  float64\n","dtypes: float64(6), int64(7), object(5)\n","memory usage: 1.4+ MB\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/q5/n9nsskgd1y7d9jkzzzmv_f780000gn/T/ipykernel_3145/820124280.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  cars[\"credit_score\"].fillna(cars[\"credit_score\"].mean(), inplace=True)\n","/var/folders/q5/n9nsskgd1y7d9jkzzzmv_f780000gn/T/ipykernel_3145/820124280.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n","The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n","\n","For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n","\n","\n","  cars[\"annual_mileage\"].fillna(cars[\"annual_mileage\"].mean(), inplace=True)\n"]}],"source":["# We can see there are some NaN values in the columns \"credit_score\" and \"annual_mileage\".\n","# Fill missing values with the mean\n","cars[\"credit_score\"].fillna(cars[\"credit_score\"].mean(), inplace=True)\n","cars[\"annual_mileage\"].fillna(cars[\"annual_mileage\"].mean(), inplace=True)\n","\n","# Check data info again\n","cars.info()"]},{"cell_type":"code","execution_count":3,"id":"71b452fd-891b-45a2-a562-3481f2249951","metadata":{"executionCancelledAt":null,"executionTime":804,"id":"71b452fd-891b-45a2-a562-3481f2249951","lastExecutedAt":1706985813301,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Now we need to filter the dataset so we can create a model per feature\n\n# First we create a empty list to store the model results\nmodels = []\n\n# Select the feature columns\nfeatures = cars.drop(columns=[\"id\", \"outcome\"]).columns\n\n# Loop through feature\nfor feature in features:\n    # Create a model\n    model = logit(f\"outcome ~ {feature}\", data=cars).fit()\n    # Append to the mode result list\n    models.append(model)\n    \n# Check model result list\nprint(models)","outputId":"b69956af-9de2-48dc-a6c3-d48778d8035f","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Optimization terminated successfully.\n","         Current function value: 0.511794\n","         Iterations 6\n","Optimization terminated successfully.\n","         Current function value: 0.615951\n","         Iterations 5\n","Optimization terminated successfully.\n","         Current function value: 0.467092\n","         Iterations 8\n","Optimization terminated successfully.\n","         Current function value: 0.603742\n","         Iterations 5\n","Optimization terminated successfully.\n","         Current function value: 0.531499\n","         Iterations 6\n","Optimization terminated successfully.\n","         Current function value: 0.572557\n","         Iterations 6\n","Optimization terminated successfully.\n","         Current function value: 0.552412\n","         Iterations 5\n","Optimization terminated successfully.\n","         Current function value: 0.572668\n","         Iterations 6\n","Optimization terminated successfully.\n","         Current function value: 0.586659\n","         Iterations 5\n","Optimization terminated successfully.\n","         Current function value: 0.595431\n","         Iterations 5\n","Optimization terminated successfully.\n","         Current function value: 0.617345\n","         Iterations 5\n","Optimization terminated successfully.\n","         Current function value: 0.605716\n","         Iterations 5\n","Optimization terminated successfully.\n","         Current function value: 0.621700\n","         Iterations 5\n","Optimization terminated successfully.\n","         Current function value: 0.558922\n","         Iterations 7\n","Optimization terminated successfully.\n","         Current function value: 0.598699\n","         Iterations 6\n","Optimization terminated successfully.\n","         Current function value: 0.549220\n","         Iterations 7\n"]},{"data":{"text/plain":["[<statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x1396c60c0>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f722270>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f7231a0>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f723bc0>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f7236b0>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f768e60>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f769790>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f76a030>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f76aa50>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f76b3e0>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f76be00>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f76b350>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f789160>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f789bb0>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f78a480>,\n"," <statsmodels.discrete.discrete_model.BinaryResultsWrapper at 0x13f78af30>]"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Now we need to filter the dataset so we can create a model per feature\n","\n","# First we create a empty list to store the model results\n","models = []\n","\n","# Select the feature columns\n","features = cars.drop(columns=[\"id\", \"outcome\"]).columns\n","\n","# Loop through feature\n","for feature in features:\n","    # Create a model\n","    # This creates a logistic regression model where `outcome` is the dependent variable (what you want to predict), \n","    # and `feature` is the independent variable (what you're using to make the prediction).\n","    model = logit(f\"outcome ~ {feature}\", data=cars).fit()\n","    # Append to the mode result list\n","    models.append(model)\n","\n","# Check model result list\n","models"]},{"cell_type":"code","execution_count":4,"id":"26877ebd-786b-4d95-811e-ee4adc28e0df","metadata":{"executionCancelledAt":null,"executionTime":100,"id":"26877ebd-786b-4d95-811e-ee4adc28e0df","lastExecutedAt":1706985813401,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Now that we have the list with all the models per feature, lets calculate the accuracy, so we can select the best feature depending on the accuracy.\n\n# Remember that to calculate the accuracy of the features we need to compute the confusion matrix first.\n# accuracy = (TN + TP) / (TN + TP + FN + FP)\n\n# Empty list to store accuracies\naccuracies = []\n\n# Loop through features\nfor feature in range(len(models)):\n    # Compute the confusion matrix\n    conf_matrix = models[feature].pred_table()\n    # True Negatives\n    tn = conf_matrix[0, 0]\n    # True Positives \n    tp = conf_matrix[1, 1]\n    # False Negatives\n    fn = conf_matrix[1, 0]\n    # False Positives\n    fp = conf_matrix[0, 1]\n    # Accuracy\n    acc = (tp + tn) / (tp + tn + fp + fn)\n    # Append accuracy to accuracy list\n    accuracies.append(acc)\n    \n# Check for the feature with the hights accuracy\nbest_feature = features[accuracies.index(max(accuracies))]\nprint(f\"The feature with the highest accuracy is: {best_feature}\")","outputId":"03f319e0-77f0-4b9f-e696-75cdf1a8457f","outputsMetadata":{"0":{"height":37,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["The feature with the highest accuracy is: driving_experience\n"]}],"source":["# Now that we have the list with all the models per feature, lets calculate the accuracy, so we can select the best feature depending on the accuracy.\n","\n","# Remember that to calculate the accuracy of the features we need to compute the confusion matrix first.\n","# accuracy = (TN + TP) / (TN + TP + FN + FP)\n","\n","# Empty list to store accuracies\n","accuracies = []\n","\n","# Loop through features\n","for feature in range(len(models)):\n","    # Compute the confusion matrix\n","    conf_matrix = models[feature].pred_table()\n","    # True Negatives\n","    tn = conf_matrix[0, 0]\n","    # True Positives\n","    tp = conf_matrix[1, 1]\n","    # False Negatives\n","    fn = conf_matrix[1, 0]\n","    # False Positives\n","    fp = conf_matrix[0, 1]\n","    # Accuracy\n","    acc = (tp + tn) / (tp + tn + fp + fn)\n","    # Append accuracy to accuracy list\n","    accuracies.append(acc)\n","\n","# Check for the feature with the hights accuracy\n","best_feature = features[accuracies.index(max(accuracies))]\n","print(f\"The feature with the highest accuracy is: {best_feature}\")"]},{"cell_type":"code","execution_count":5,"id":"0918bd38-e273-417b-9b9b-9933fa100797","metadata":{"executionCancelledAt":null,"executionTime":47,"id":"0918bd38-e273-417b-9b9b-9933fa100797","lastExecutedAt":1706985813449,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Create DataFrame\nbest_feature_df = pd.DataFrame(\n    {\"best_feature\": [best_feature],\n     \"best_accuracy\": [max(accuracies)]}\n)\n\nprint(best_feature_df)","outputId":"6586d2e9-d96b-45a0-d012-8387951f7532","outputsMetadata":{"0":{"height":57,"type":"stream"}}},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>best_feature</th>\n","      <th>best_accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>driving_experience</td>\n","      <td>0.7771</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         best_feature  best_accuracy\n","0  driving_experience         0.7771"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# Create DataFrame\n","best_feature_df = pd.DataFrame(\n","    {\"best_feature\": [best_feature],\n","     \"best_accuracy\": [max(accuracies)]}\n",")\n","\n","best_feature_df"]}],"metadata":{"colab":{"provenance":[]},"editor":"DataCamp Workspace","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":5}
